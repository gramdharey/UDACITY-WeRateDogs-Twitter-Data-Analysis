{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report: act_report\n",
    "* Create a **250-word-minimum written report** called \"act_report.pdf\" or \"act_report.html\" that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Project \n",
    "### D.K. Oluwadare\n",
    "\n",
    "## Introduction\n",
    "This project demonstrates the data wrangling process for the tweet archive of Twitter user @dog_rates, @dog_rates is a Twitter account that rates people's dogs with a humorous comment about the dog. In this analysis I demonstrate the data wrangling techniques that were used to gather, assess and clean the dog twitter archive.\n",
    "\n",
    "## Project Overview\n",
    "### Gather data\n",
    "\n",
    "The following files were gathered for the analysis:\n",
    "\n",
    "* The WeRateDogs (@dog_rates) Twitter archive - This file  (archive.csv) was downloaded using Twitter's API and consists of basic tweet data for 2300+ tweets from WeRateDogs. \n",
    "\n",
    "* The tweet image predictions - i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file (image_predictions.tsv) was downloaded programmatically from Udacity.\n",
    "\n",
    "* Each tweet's retweet_count and favorite_count -This file (tweet_json) contains JSON data for each tweet indicating the retweet and favorite counts.\n",
    "\n",
    "### Assess data\n",
    "\n",
    "The three files obtained in the gathering phase were loaded into individual Pandas data frames for assessment. Each of the data frames were evaluated visually and programmatically.  \n",
    "\n",
    "### Clean data\n",
    "\n",
    "The quality and tidiness issues were cleaned using programmatic techniques such as:\n",
    "\n",
    "    • Dropping unnecessary columns from the tables\n",
    "    • Removing rows that consisted of null retweets\n",
    "    • Removal of rows with duplicate information\n",
    "    • Deleted rows that did not have any dog predictions at all\n",
    "    • Combining all three data frames into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
