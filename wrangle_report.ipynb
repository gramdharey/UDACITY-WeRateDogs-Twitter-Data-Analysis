{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Project\n",
    "\n",
    "### D.K. Oluwadare\n",
    "\n",
    "## Introduction\n",
    "This project demonstrates the data wrangling process for the tweet archive of Twitter user @dog_rates, @dog_rates is a Twitter account that rates people's dogs with a humorous comment about the dog. In this analysis I demonstrate the data wrangling techniques that were used to gather, assess and clean the dog twitter archive.\n",
    "\n",
    "## Project Overview\n",
    "### Gather data\n",
    "\n",
    "The following files were gathered for the analysis:\n",
    "\n",
    "* The WeRateDogs (@dog_rates) Twitter archive - This file  (archive.csv) was downloaded using Twitter's API and consists of basic tweet data for 2300+ tweets from WeRateDogs. \n",
    "\n",
    "* The tweet image predictions - i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file (image_predictions.tsv) was downloaded programmatically from Udacity.\n",
    "\n",
    "* Each tweet's retweet_count and favorite_count -This file (tweet_json) contains JSON data for each tweet indicating the retweet and favorite counts.\n",
    "\n",
    "\n",
    "\n",
    "### Assess data\n",
    "\n",
    "The three files obtained in the gathering phase were loaded into individual Pandas data frames for assessment. Each of the data frames were evaluated visually and programmatically.  \n",
    "\n",
    "\n",
    "#### Virtual assessment\n",
    "The involves mere looking at the data virtually to have an insight of what to work with in the data. Virtual assessment doesnt give detailed understanding of a data. I used some basic pandas methods like (.head(), .shape) to know the columns and rows to expect when doing my analysis\n",
    "\n",
    "#### Programatic assessment\n",
    "\n",
    "Programatic assessment helped me idenified various quality and tidiness issues. The quality and tidiness issues that would be cleaned using programmatic techniques includes but not limited to:\n",
    "\n",
    "    • Dropping unnecessary columns from the tables\n",
    "    • Removing rows that consisted of null retweets\n",
    "    • Removal of rows with duplicate information\n",
    "    • Deleted rows that did not have any dog predictions at all\n",
    "    • Combining all three data frames into a single data frame\n",
    "\n",
    "\n",
    "\n",
    "### Clean data\n",
    "\n",
    "\n",
    "#### Quality\n",
    "\n",
    "1. The column 'id' should be changed to tweet_id in the *newapi* Table \n",
    "\n",
    "2. Some uppercase and lowercase letters identified in columns 'p1', 'p2', and 'p3' in the *image_prediction* Table\n",
    "\n",
    "3. 'text' column has unnecesary HTML code in the *twitter_archive* Table\n",
    "\n",
    "4. Missing values in columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id,      retweeted_status_timestamp, and expanded_urls in the *twitter_archive* Table\n",
    "\n",
    "5. 'timestamp' should be a datetime64 dtype as well in the *Twitter_archive* Table \n",
    "\n",
    "6. Remove the 'source' column in the *twitter_archive* Table\n",
    "\n",
    "7. Drops rows with duplicates in the jpg_url column\n",
    "\n",
    "8. Change timestamp format from \"2017-07-26 15:59:51+00:00\" to \"2017, 2016, 2015....\"\n",
    "\n",
    "#### Tidiness\n",
    "    \n",
    "1. Merged all three tables into one.\n",
    "\n",
    "2. Dog tests are spread in three columns.\n",
    "\n",
    "\n",
    "\n",
    "### Analyzing, Visualization and Storing\n",
    "INSIGHT 1 : DOG CATEGORIES WITH FAVOURITE COUNTS\n",
    "INSIGHT 2 : DOG WITH THE MOST POPULAR NAME\n",
    "INSIGHT 3 : TOP 20 DOG NAMES WITH RETWEETS RATE\n",
    "INSIGHT 4 : DOG BREED WITH HIGHEST MEAN RATE NUMERATOR, AND HIGHEST VALUE COUNTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "* Handling error from writing (w) a json_file wih the twitter API tokens.\n",
    "* The Dog tests spread in three columns had so many 'none' rows, afetr combining it into dogtypes, i had to remove the rows and worked with the ones visible to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/\n",
    "https://chrisalbon.com/code/python/data_wrangling/pandas_apply_operations_to_dataframes/\n",
    "https://stackabuse.com/reading-and-writing-json-files-in-python-with-pandas/\n",
    "https://www.youtube.com/watch?v=SLM5R59-b6g\n",
    "https://www.youtube.com/watch?v=MbKrSmoMads\n",
    "https://www.youtube.com/watch?v=6GUZXDef2U0\n",
    "https://seaborn.pydata.org/tutorial/function_overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
